{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnomalyDetection-Autoencoders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZrrYzxMlfpBCnGGS5QIKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggranadillo21/Mytest/blob/master/AnomalyDetection_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "94zLghPXZaC5",
        "outputId": "f24cab58-cfee-4de0-dcbc-a3a98eb00597"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Duration</td>\n",
              "      <td>Proto</td>\n",
              "      <td>SrcPt</td>\n",
              "      <td>DstPt</td>\n",
              "      <td>Packets</td>\n",
              "      <td>Bytes</td>\n",
              "      <td>Flags</td>\n",
              "      <td>Tos</td>\n",
              "      <td>class</td>\n",
              "      <td>Packets_speed</td>\n",
              "      <td>Bytes_speed</td>\n",
              "      <td>Hour</td>\n",
              "      <td>Min</td>\n",
              "      <td>Sec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>33877</td>\n",
              "      <td>443</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>660000</td>\n",
              "      <td>36</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.042</td>\n",
              "      <td>6</td>\n",
              "      <td>80</td>\n",
              "      <td>52335</td>\n",
              "      <td>2</td>\n",
              "      <td>413</td>\n",
              "      <td>26</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>47.6190476190476</td>\n",
              "      <td>9833.33333333333</td>\n",
              "      <td>24</td>\n",
              "      <td>54</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.215</td>\n",
              "      <td>6</td>\n",
              "      <td>51696</td>\n",
              "      <td>80</td>\n",
              "      <td>8</td>\n",
              "      <td>1350</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>37.2093023255814</td>\n",
              "      <td>6279.06976744186</td>\n",
              "      <td>28</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.143</td>\n",
              "      <td>6</td>\n",
              "      <td>37251</td>\n",
              "      <td>443</td>\n",
              "      <td>4</td>\n",
              "      <td>1810</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.972027972028</td>\n",
              "      <td>12657.3426573427</td>\n",
              "      <td>38</td>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0         1      2      3   ...                11    12   13   14\n",
              "0  NaN  Duration  Proto  SrcPt  ...       Bytes_speed  Hour  Min  Sec\n",
              "1  1.0         0      6  33877  ...            660000    36   30    3\n",
              "2  2.0     0.042      6     80  ...  9833.33333333333    24   54    3\n",
              "3  3.0     0.215      6  51696  ...  6279.06976744186    28   50    0\n",
              "4  4.0     0.143      6  37251  ...  12657.3426573427    38   32    6\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
        "\n",
        "# Download the dataset\n",
        "#PATH_TO_DATA = 'http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv'\n",
        "PATH_TO_DATA ='muestra1.csv'\n",
        "data = pd.read_csv(PATH_TO_DATA, header=None)\n",
        "data = data.drop(0, axis=0)\n",
        "data = data.drop(0, axis=1)\n",
        "data = data.drop(12, axis=1)\n",
        "data = data.drop(13, axis=1)\n",
        "data.head()\n",
        "#data.shape\n",
        "# data shape\n",
        "# (10487, 15)\n",
        "#Label 1 denotes the observation as an anomaly and label 0 denotes the observation as normal."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9th column is the target\n",
        "# 1 = anomaly, 0 = normal\n",
        "\n",
        "x_train = pd.read_csv(\"x_train.csv\", header=None)\n",
        "x_train = x_train.drop(0, axis=0)\n",
        "x_train = x_train.drop(0, axis=1)\n",
        "x_train = x_train.drop(x_train.columns[[10, 11, 12]], axis=1)\n",
        "\n",
        "y_train = pd.read_csv(\"y_train.csv\", header=None)\n",
        "y_train = y_train.drop(0, axis=0)\n",
        "y_train = y_train.drop(0, axis=1)\n",
        "\n",
        "x_test = pd.read_csv(\"x_test.csv\", header=None)\n",
        "x_test = x_test.drop(0, axis=0)\n",
        "x_test = x_test.drop(0, axis=1)\n",
        "x_test = x_test.drop(x_test.columns[[10, 11, 12]], axis=1)\n",
        "\n",
        "y_test = pd.read_csv(\"y_test.csv\", header=None)\n",
        "y_test = y_test.drop(0, axis=0)\n",
        "y_test = y_test.drop(0, axis=1)\n",
        "\n",
        "\n",
        "# min max scale the input data\n",
        "min_max_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_train_scaled = min_max_scaler.fit_transform(x_train.copy())\n",
        "x_test_scaled = min_max_scaler.transform(x_test.copy())\n",
        "\n",
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6jsbUlcyZz44",
        "outputId": "49ca0ab3-743d-4ee7-edd9-4f3a2417d710"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>33877</td>\n",
              "      <td>443</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.042</td>\n",
              "      <td>6</td>\n",
              "      <td>80</td>\n",
              "      <td>52335</td>\n",
              "      <td>2</td>\n",
              "      <td>413</td>\n",
              "      <td>26</td>\n",
              "      <td>32</td>\n",
              "      <td>47.6190476190476</td>\n",
              "      <td>9833.33333333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.215</td>\n",
              "      <td>6</td>\n",
              "      <td>51696</td>\n",
              "      <td>80</td>\n",
              "      <td>8</td>\n",
              "      <td>1350</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>37.2093023255814</td>\n",
              "      <td>6279.06976744186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.143</td>\n",
              "      <td>6</td>\n",
              "      <td>37251</td>\n",
              "      <td>443</td>\n",
              "      <td>4</td>\n",
              "      <td>1810</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>27.972027972028</td>\n",
              "      <td>12657.3426573427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>35641</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6996</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>60691</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>66</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6997</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>80</td>\n",
              "      <td>42308</td>\n",
              "      <td>1</td>\n",
              "      <td>54</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>10000</td>\n",
              "      <td>540000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6998</th>\n",
              "      <td>0.183</td>\n",
              "      <td>6</td>\n",
              "      <td>54145</td>\n",
              "      <td>443</td>\n",
              "      <td>4</td>\n",
              "      <td>2853</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>21.8579234972678</td>\n",
              "      <td>15590.1639344262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6999</th>\n",
              "      <td>0.038</td>\n",
              "      <td>17</td>\n",
              "      <td>53</td>\n",
              "      <td>41689</td>\n",
              "      <td>2</td>\n",
              "      <td>222</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>52.6315789473684</td>\n",
              "      <td>5842.1052631579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7000</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>56745</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>55</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>10000</td>\n",
              "      <td>550000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         1   2      3      4   ...  7   8                 9                 10\n",
              "1         0   6  33877    443  ...  16   0             10000            660000\n",
              "2     0.042   6     80  52335  ...  26  32  47.6190476190476  9833.33333333333\n",
              "3     0.215   6  51696     80  ...  26   0  37.2093023255814  6279.06976744186\n",
              "4     0.143   6  37251    443  ...  24   0   27.972027972028  12657.3426573427\n",
              "5         0   6  35641     80  ...  16   0             10000            660000\n",
              "...     ...  ..    ...    ...  ...  ..  ..               ...               ...\n",
              "6996      0   6  60691     80  ...  16   0             10000            660000\n",
              "6997      0   6     80  42308  ...   4  32             10000            540000\n",
              "6998  0.183   6  54145    443  ...  24   0  21.8579234972678  15590.1639344262\n",
              "6999  0.038  17     53  41689  ...   0   0  52.6315789473684   5842.1052631579\n",
              "7000      0   6  56745     80  ...  16   0             10000            550000\n",
              "\n",
              "[7000 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model by subclassing Model class in tensorflow\n",
        "class AutoEncoder(Model):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  output_units: int\n",
        "    Number of output units\n",
        "  \n",
        "  code_size: int\n",
        "    Number of units in bottle neck\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, output_units, code_size=8):\n",
        "    super().__init__()\n",
        "    self.encoder = Sequential([\n",
        "      Dense(512, activation='relu'),\n",
        "      Dropout(0.01),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dropout(0.01),\n",
        "      Dense(128, activation='relu'),\n",
        "      Dropout(0.01),\n",
        "      Dense(code_size, activation='relu')\n",
        "    ])\n",
        "    self.decoder = Sequential([\n",
        "      Dense(128, activation='relu'),\n",
        "      Dropout(0.01),\n",
        "      Dense(256, activation='relu'),\n",
        "      Dropout(0.01),\n",
        "      Dense(512, activation='relu'),\n",
        "      Dropout(0.01),\n",
        "      Dense(output_units, activation='sigmoid')\n",
        "    ])\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    encoded = self.encoder(inputs)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "  \n",
        "model = AutoEncoder(output_units=x_train_scaled.shape[1])\n",
        "# configurations of model\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "\n",
        "history = model.fit(\n",
        "    x_train_scaled,\n",
        "    x_train_scaled,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_data=(x_test_scaled, x_test_scaled)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOd_-DT_aiSd",
        "outputId": "6d154d36-4205-4719-fde4-9f101910283f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "55/55 [==============================] - 4s 34ms/step - loss: 0.3353 - accuracy: 0.4014 - val_loss: 0.2264 - val_accuracy: 0.6041\n",
            "Epoch 2/100\n",
            "55/55 [==============================] - 1s 25ms/step - loss: 0.2119 - accuracy: 0.7739 - val_loss: 0.1973 - val_accuracy: 0.9406\n",
            "Epoch 3/100\n",
            "55/55 [==============================] - 1s 25ms/step - loss: 0.1943 - accuracy: 0.9080 - val_loss: 0.1915 - val_accuracy: 0.9134\n",
            "Epoch 4/100\n",
            "55/55 [==============================] - 2s 27ms/step - loss: 0.1922 - accuracy: 0.9150 - val_loss: 0.1899 - val_accuracy: 0.9426\n",
            "Epoch 5/100\n",
            "55/55 [==============================] - 1s 25ms/step - loss: 0.1912 - accuracy: 0.9201 - val_loss: 0.1894 - val_accuracy: 0.9426\n",
            "Epoch 6/100\n",
            "55/55 [==============================] - 1s 23ms/step - loss: 0.1907 - accuracy: 0.9241 - val_loss: 0.1894 - val_accuracy: 0.9203\n",
            "Epoch 7/100\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.1904 - accuracy: 0.9277 - val_loss: 0.1887 - val_accuracy: 0.9168\n",
            "Epoch 8/100\n",
            "55/55 [==============================] - 1s 26ms/step - loss: 0.1900 - accuracy: 0.9309 - val_loss: 0.1878 - val_accuracy: 0.9492\n",
            "Epoch 9/100\n",
            "55/55 [==============================] - 1s 23ms/step - loss: 0.1895 - accuracy: 0.9350 - val_loss: 0.1868 - val_accuracy: 0.9555\n",
            "Epoch 10/100\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.1890 - accuracy: 0.9367 - val_loss: 0.1862 - val_accuracy: 0.9699\n",
            "Epoch 11/100\n",
            "55/55 [==============================] - 1s 19ms/step - loss: 0.1885 - accuracy: 0.9411 - val_loss: 0.1859 - val_accuracy: 0.9664\n",
            "Epoch 12/100\n",
            "55/55 [==============================] - 1s 24ms/step - loss: 0.1883 - accuracy: 0.9397 - val_loss: 0.1855 - val_accuracy: 0.9578\n",
            "Epoch 13/100\n",
            "55/55 [==============================] - 1s 26ms/step - loss: 0.1880 - accuracy: 0.9421 - val_loss: 0.1852 - val_accuracy: 0.9647\n",
            "Epoch 14/100\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.1877 - accuracy: 0.9447 - val_loss: 0.1850 - val_accuracy: 0.9532\n",
            "Epoch 15/100\n",
            "55/55 [==============================] - 1s 25ms/step - loss: 0.1876 - accuracy: 0.9450 - val_loss: 0.1854 - val_accuracy: 0.9515\n",
            "Epoch 16/100\n",
            "55/55 [==============================] - 1s 26ms/step - loss: 0.1875 - accuracy: 0.9471 - val_loss: 0.1842 - val_accuracy: 0.9662\n",
            "Epoch 17/100\n",
            "55/55 [==============================] - 1s 22ms/step - loss: 0.1873 - accuracy: 0.9489 - val_loss: 0.1847 - val_accuracy: 0.9618\n",
            "Epoch 18/100\n",
            "55/55 [==============================] - 1s 23ms/step - loss: 0.1872 - accuracy: 0.9470 - val_loss: 0.1842 - val_accuracy: 0.9578\n",
            "Epoch 19/100\n",
            "55/55 [==============================] - 1s 25ms/step - loss: 0.1872 - accuracy: 0.9460 - val_loss: 0.1841 - val_accuracy: 0.9581\n",
            "Epoch 20/100\n",
            "55/55 [==============================] - 1s 23ms/step - loss: 0.1871 - accuracy: 0.9460 - val_loss: 0.1841 - val_accuracy: 0.9527\n",
            "Epoch 21/100\n",
            "55/55 [==============================] - 1s 20ms/step - loss: 0.1871 - accuracy: 0.9494 - val_loss: 0.1842 - val_accuracy: 0.9575\n",
            "Epoch 22/100\n",
            "55/55 [==============================] - 1s 24ms/step - loss: 0.1870 - accuracy: 0.9519 - val_loss: 0.1837 - val_accuracy: 0.9449\n",
            "Epoch 23/100\n",
            "55/55 [==============================] - 2s 30ms/step - loss: 0.1870 - accuracy: 0.9516 - val_loss: 0.1838 - val_accuracy: 0.9578\n",
            "Epoch 24/100\n",
            "55/55 [==============================] - 1s 19ms/step - loss: 0.1869 - accuracy: 0.9520 - val_loss: 0.1835 - val_accuracy: 0.9527\n",
            "Epoch 25/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1868 - accuracy: 0.9540 - val_loss: 0.1834 - val_accuracy: 0.9527\n",
            "Epoch 26/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1868 - accuracy: 0.9540 - val_loss: 0.1834 - val_accuracy: 0.9530\n",
            "Epoch 27/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1868 - accuracy: 0.9571 - val_loss: 0.1833 - val_accuracy: 0.9509\n",
            "Epoch 28/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1867 - accuracy: 0.9596 - val_loss: 0.1833 - val_accuracy: 0.9495\n",
            "Epoch 29/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1867 - accuracy: 0.9574 - val_loss: 0.1835 - val_accuracy: 0.9487\n",
            "Epoch 30/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1867 - accuracy: 0.9541 - val_loss: 0.1833 - val_accuracy: 0.9547\n",
            "Epoch 31/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1867 - accuracy: 0.9550 - val_loss: 0.1833 - val_accuracy: 0.9472\n",
            "Epoch 32/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1866 - accuracy: 0.9557 - val_loss: 0.1834 - val_accuracy: 0.9446\n",
            "Epoch 33/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1866 - accuracy: 0.9591 - val_loss: 0.1831 - val_accuracy: 0.9524\n",
            "Epoch 34/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1866 - accuracy: 0.9590 - val_loss: 0.1836 - val_accuracy: 0.9524\n",
            "Epoch 35/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1866 - accuracy: 0.9619 - val_loss: 0.1831 - val_accuracy: 0.9547\n",
            "Epoch 36/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9594 - val_loss: 0.1831 - val_accuracy: 0.9481\n",
            "Epoch 37/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1865 - accuracy: 0.9607 - val_loss: 0.1829 - val_accuracy: 0.9507\n",
            "Epoch 38/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9630 - val_loss: 0.1833 - val_accuracy: 0.9452\n",
            "Epoch 39/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1865 - accuracy: 0.9561 - val_loss: 0.1828 - val_accuracy: 0.9515\n",
            "Epoch 40/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9627 - val_loss: 0.1828 - val_accuracy: 0.9541\n",
            "Epoch 41/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9624 - val_loss: 0.1839 - val_accuracy: 0.9504\n",
            "Epoch 42/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9609 - val_loss: 0.1832 - val_accuracy: 0.9573\n",
            "Epoch 43/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9600 - val_loss: 0.1839 - val_accuracy: 0.9509\n",
            "Epoch 44/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1866 - accuracy: 0.9569 - val_loss: 0.1832 - val_accuracy: 0.9489\n",
            "Epoch 45/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9549 - val_loss: 0.1823 - val_accuracy: 0.9507\n",
            "Epoch 46/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1864 - accuracy: 0.9616 - val_loss: 0.1823 - val_accuracy: 0.9507\n",
            "Epoch 47/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1864 - accuracy: 0.9617 - val_loss: 0.1819 - val_accuracy: 0.9495\n",
            "Epoch 48/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1864 - accuracy: 0.9629 - val_loss: 0.1825 - val_accuracy: 0.9498\n",
            "Epoch 49/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9629 - val_loss: 0.1824 - val_accuracy: 0.9561\n",
            "Epoch 50/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9641 - val_loss: 0.1825 - val_accuracy: 0.9596\n",
            "Epoch 51/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9659 - val_loss: 0.1825 - val_accuracy: 0.9558\n",
            "Epoch 52/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9631 - val_loss: 0.1823 - val_accuracy: 0.9627\n",
            "Epoch 53/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9621 - val_loss: 0.1825 - val_accuracy: 0.9587\n",
            "Epoch 54/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9634 - val_loss: 0.1827 - val_accuracy: 0.9598\n",
            "Epoch 55/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9637 - val_loss: 0.1824 - val_accuracy: 0.9475\n",
            "Epoch 56/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9649 - val_loss: 0.1824 - val_accuracy: 0.9573\n",
            "Epoch 57/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9654 - val_loss: 0.1825 - val_accuracy: 0.9616\n",
            "Epoch 58/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1863 - accuracy: 0.9637 - val_loss: 0.1824 - val_accuracy: 0.9630\n",
            "Epoch 59/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9679 - val_loss: 0.1826 - val_accuracy: 0.9616\n",
            "Epoch 60/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9643 - val_loss: 0.1823 - val_accuracy: 0.9653\n",
            "Epoch 61/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9649 - val_loss: 0.1826 - val_accuracy: 0.9667\n",
            "Epoch 62/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9696 - val_loss: 0.1821 - val_accuracy: 0.9650\n",
            "Epoch 63/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1863 - accuracy: 0.9694 - val_loss: 0.1826 - val_accuracy: 0.9662\n",
            "Epoch 64/100\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.1862 - accuracy: 0.9686 - val_loss: 0.1824 - val_accuracy: 0.9621\n",
            "Epoch 65/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9676 - val_loss: 0.1825 - val_accuracy: 0.9581\n",
            "Epoch 66/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9654 - val_loss: 0.1819 - val_accuracy: 0.9679\n",
            "Epoch 67/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9663 - val_loss: 0.1824 - val_accuracy: 0.9458\n",
            "Epoch 68/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9660 - val_loss: 0.1818 - val_accuracy: 0.9745\n",
            "Epoch 69/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9669 - val_loss: 0.1825 - val_accuracy: 0.9733\n",
            "Epoch 70/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9683 - val_loss: 0.1817 - val_accuracy: 0.9644\n",
            "Epoch 71/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9664 - val_loss: 0.1822 - val_accuracy: 0.9702\n",
            "Epoch 72/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9673 - val_loss: 0.1818 - val_accuracy: 0.9739\n",
            "Epoch 73/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9681 - val_loss: 0.1826 - val_accuracy: 0.9791\n",
            "Epoch 74/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9703 - val_loss: 0.1827 - val_accuracy: 0.9773\n",
            "Epoch 75/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1861 - accuracy: 0.9691 - val_loss: 0.1831 - val_accuracy: 0.9756\n",
            "Epoch 76/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1861 - accuracy: 0.9689 - val_loss: 0.1820 - val_accuracy: 0.9756\n",
            "Epoch 77/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1861 - accuracy: 0.9679 - val_loss: 0.1825 - val_accuracy: 0.9753\n",
            "Epoch 78/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9671 - val_loss: 0.1824 - val_accuracy: 0.9753\n",
            "Epoch 79/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9701 - val_loss: 0.1825 - val_accuracy: 0.9676\n",
            "Epoch 80/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9694 - val_loss: 0.1826 - val_accuracy: 0.9736\n",
            "Epoch 81/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9667 - val_loss: 0.1834 - val_accuracy: 0.9662\n",
            "Epoch 82/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9689 - val_loss: 0.1833 - val_accuracy: 0.9653\n",
            "Epoch 83/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9679 - val_loss: 0.1823 - val_accuracy: 0.9816\n",
            "Epoch 84/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9710 - val_loss: 0.1825 - val_accuracy: 0.9819\n",
            "Epoch 85/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9727 - val_loss: 0.1820 - val_accuracy: 0.9765\n",
            "Epoch 86/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1861 - accuracy: 0.9686 - val_loss: 0.1825 - val_accuracy: 0.9796\n",
            "Epoch 87/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9729 - val_loss: 0.1828 - val_accuracy: 0.9802\n",
            "Epoch 88/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1861 - accuracy: 0.9684 - val_loss: 0.1825 - val_accuracy: 0.9739\n",
            "Epoch 89/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9664 - val_loss: 0.1824 - val_accuracy: 0.9756\n",
            "Epoch 90/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9706 - val_loss: 0.1826 - val_accuracy: 0.9779\n",
            "Epoch 91/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9691 - val_loss: 0.1824 - val_accuracy: 0.9748\n",
            "Epoch 92/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9716 - val_loss: 0.1820 - val_accuracy: 0.9670\n",
            "Epoch 93/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9684 - val_loss: 0.1835 - val_accuracy: 0.9679\n",
            "Epoch 94/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1865 - accuracy: 0.9609 - val_loss: 0.1822 - val_accuracy: 0.9756\n",
            "Epoch 95/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1861 - accuracy: 0.9671 - val_loss: 0.1820 - val_accuracy: 0.9725\n",
            "Epoch 96/100\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.1862 - accuracy: 0.9737 - val_loss: 0.1830 - val_accuracy: 0.9679\n",
            "Epoch 97/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1869 - accuracy: 0.9541 - val_loss: 0.1843 - val_accuracy: 0.9662\n",
            "Epoch 98/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1867 - accuracy: 0.9541 - val_loss: 0.1798 - val_accuracy: 0.9624\n",
            "Epoch 99/100\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.1864 - accuracy: 0.9639 - val_loss: 0.1834 - val_accuracy: 0.9558\n",
            "Epoch 100/100\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.1862 - accuracy: 0.9660 - val_loss: 0.1822 - val_accuracy: 0.9776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSLE Loss')\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ibefIEHic_Am",
        "outputId": "8f9feaf4-edb9-4f19-b757-66fa6e2da4ad"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_threshold(model, x_train_scaled):\n",
        "  reconstructions = model.predict(x_train_scaled)\n",
        "  # provides losses of individual instances\n",
        "  reconstruction_errors = tf.keras.losses.msle(reconstructions, x_train_scaled)\n",
        "  # threshold for anomaly scores\n",
        "  threshold = np.mean(reconstruction_errors.numpy()) \\\n",
        "      + np.std(reconstruction_errors.numpy())\n",
        "  return threshold\n",
        "\n",
        "def get_predictions(model, x_test_scaled, threshold):\n",
        "  predictions = model.predict(x_test_scaled)\n",
        "  # provides losses of individual instances\n",
        "  errors = tf.keras.losses.msle(predictions, x_test_scaled)\n",
        "  # 1 = anomaly, 0 = normal\n",
        "  anomaly_mask = pd.Series(errors) > threshold\n",
        "  preds = anomaly_mask.map(lambda x: 1 if x == True else 0)\n",
        "  return preds\n",
        "\n",
        "threshold = find_threshold(model, x_train_scaled)\n",
        "print(f\"Threshold: {threshold}\")\n",
        "# Threshold: 0.01001314025746261\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XS_J7WidSUu",
        "outputId": "ce1c797d-d7fc-495f-949c-657bbf0a2a0a"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold: 9.341444788289367e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_predictions(model, x_test_scaled, threshold)\n",
        "predictions = pd.DataFrame(predictions)\n",
        "predictions = predictions.rename(columns={0:'class'})\n",
        "y_test = y_test.rename(columns={1:'class'})\n",
        "y_test[\"class\"] = y_test[\"class\"].astype(str).astype(int)\n",
        "\n",
        "accuracy_score(predictions, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF-OaL-adeEo",
        "outputId": "08053e4e-a09b-492a-84e1-4a87cf7b76a1"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6858864027538726"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2ZOfbt6t3wUJ",
        "outputId": "66c398d7-548c-405c-8a5d-d06b32c77963"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3481</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3482</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3483</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3484</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3485</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3486 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      class\n",
              "0         1\n",
              "1         1\n",
              "2         1\n",
              "3         1\n",
              "4         1\n",
              "...     ...\n",
              "3481      1\n",
              "3482      1\n",
              "3483      1\n",
              "3484      1\n",
              "3485      1\n",
              "\n",
              "[3486 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    }
  ]
}